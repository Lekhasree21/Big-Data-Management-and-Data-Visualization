from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler

categories = ['Gender', 'Age','Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage']
categs = []
for categoric in categories:
    stringIndexer = StringIndexer(inputCol = categoric, outputCol = categoric + 'Index')
    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoric + "classVec"])
    categs += [stringIndexer, encoder]
string_label = StringIndexer(inputCol = ' Response', outputCol = 'label')
categs += [string_label]
numerics = ['Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']
input_assemble = [c + "classVec" for c in categories] + numerics
assembling = VectorAssembler(inputCols=input_assemble, outputCol="features")
categs += [assembling]

from pyspark.ml import Pipeline
pipeline = Pipeline(stages = categs)
pipelineModel = pipeline.fit(spark_df)
df = pipelineModel.transform(spark_df)
selectedCols = ['label', 'features'] + cols
df = df.select(selectedCols)
df.printSchema()

training_data, testing_data = df.randomSplit([0.7, 0.3], seed = 2018)
print("training_data count: " + str(training_data.count()))
print("testing_data count: " + str(testing_data.count()))

from pyspark.ml.classification import RandomForestClassifier
rfc = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')
rfcModel = rfc.fit(training_data)
predictions = rfcModel.transform(testing_data)

from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluating = BinaryClassificationEvaluator()
print("testing_data Area Under ROC " + str(evaluating.evaluate(predictions, {evaluating.metricName: "areaUnderROC"})))
 
quit()

stop-all.sh

jps
